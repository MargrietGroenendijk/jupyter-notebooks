{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://aif360.mybluemix.net/static/images/logo.png\" width=\"100\" align=\"left\">\n",
    "\n",
    "\n",
    "\n",
    "#  &nbsp;&nbsp;&nbsp; Beyond Accuracy: Fairness in Machine Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**November 2020 -  Margriet Groenendijk** \n",
    "\n",
    "*Notebook for the [Digital Developer Conference - Data & AI](https://developer.ibm.com/conferences/digital-developer-conference-data-ai)*\n",
    "\n",
    "Full instructions on how to run this notebook in Watson Studio are [here](https://ibm-developer.gitbook.io/fair-and-explainable-ai/beyond-accuracy)\n",
    "\n",
    "*Code from [these examples](https://github.com/Trusted-AI/AIF360/tree/master/examples) is used and adapted*\n",
    "\n",
    "## Description\n",
    "\n",
    "Building accurate machine learning models is not always good enough, especially when predictions are used to make decisions that impact peoples lives. In addition, the fairness of a model becomes very important when decisions need be fully trusted.\n",
    "\n",
    "This notebook gives practical examples to define and quantify the fairness of both data and models, exploring algorithms to detect bias and disparity in data, and mitigate bias in both data and models.\n",
    "\n",
    "Go through the notebook to get to know more about the fairness concepts and how to explore bias in your own data and models. You will learn about the definitions and algorithms of bias and how to apply them.\n",
    "\n",
    "## Outline\n",
    "\n",
    "In this session debiasing techniques will be explored that can be implemented by using the open source toolkit [AI Fairness 360](https://github.com/IBM/AIF360). \n",
    "\n",
    "[1. Introduction](#intro)\n",
    "\n",
    "[2. AI fairness metrics](#metrics)\n",
    "\n",
    "* [2.1 Install aif360 and import packages](#install)\n",
    "* [2.2 Exploring data](#explore)\n",
    "* [2.3 Exploring bias metrics](#bias)\n",
    "\n",
    "[3. Model building](#model)\n",
    " \n",
    "* [3.1 Train on the original data](#original) \n",
    " \n",
    "[4. AI fairness algorithms](#algorithms)\n",
    "\n",
    "* [4.1 Pre-processing](#preproc)\n",
    "* [4.2 In-processing](#inproc)\n",
    "* [4.3 Post-processing](#postproc)\n",
    "\n",
    "[5. More resources](#resources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"intro\"></a>\n",
    "# 1. Introduction\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    " <b>In the UK this happened...</b> \n",
    "</div>\n",
    "\n",
    "* A model was used to estimate students grades\n",
    "* Based on previous grades, the school they went, the average for the school, etc.\n",
    "* Impacting the chance of getting accepted by universities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/MargrietGroenendijk/gitbooks2/blob/master/files/Alevels.png?raw=true\" width=\"1000\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    " <b>This model might have been accurate. But is this fair?</b> \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    " <b>How can you avoid this?</b> \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    " <b>Let's explore fairness, and how to define and reduce bias in data and models</b> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"metrics\"></a>\n",
    "# 2. AI fairness metrics\n",
    "\n",
    "Throughout this notebook [aif360](https://github.com/Trusted-AI/AIF360) is used. This is a Python package that includes a comprehensive set of metrics for datasets and models to test for biases, explanations for these metrics, and algorithms to mitigate bias in datasets and models. Find more resources and an interactive demo [here](http://aif360.mybluemix.net/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"install\"></a>\n",
    "## 2.1 Install aif360  and import packages\n",
    "\n",
    "To run this notebook in Watson Studio, you first have to install the following packages. \n",
    "\n",
    ">NOTE: for other environments you can find more detailed installation instructions [here](https://github.com/Trusted-AI/AIF360#python).\n",
    "\n",
    "#### Install the packages by uncommenting the following three lines and then running the cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install aif360\n",
    "#!pip install cvxpy\n",
    "#!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import all packages that will be used in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"../\")  \n",
    "\n",
    "# data exploration\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "# aif360 data, metrics and algorithms\n",
    "from aif360.datasets import GermanDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from aif360.algorithms.preprocessing.optim_preproc import OptimPreproc\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_german\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.distortion_functions import get_distortion_german\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.opt_tools import OptTools\n",
    "from aif360.algorithms.postprocessing.reject_option_classification import RejectOptionClassification\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"explore\"></a>\n",
    "## 2.2 Exploring data\n",
    "\n",
    "A [dataset](https://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29) with good or bad credit risks described by a set of attributes will be used for the examples in this notebook.\n",
    "\n",
    "This is one of the [datasets](https://aif360.readthedocs.io/en/latest/modules/datasets.html#module-aif360.datasets) used in `aif360` and has it's own [class](https://aif360.readthedocs.io/en/latest/modules/generated/aif360.datasets.GermanDataset.html#aif360.datasets.GermanDataset). \n",
    "\n",
    "### Load data\n",
    "\n",
    "When loading the data into the notebook with `aif360` it is assumed that the file can be accessed from a specific location. \n",
    "\n",
    "#### Create a folder and then download the data into this new folder if it is not there:\n",
    "(This will work both locally and on Watson Studio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aif360_location = !python -c \"from distutils.sysconfig import get_python_lib; print(get_python_lib())\"\n",
    "import os\n",
    "install_loc = os.path.join(aif360_location[0], \"aif360/data/raw/german/\")\n",
    "%cd $install_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -N ftp://ftp.ics.uci.edu/pub/machine-learning-databases/statlog/german/german.data\n",
    "!wget -N ftp://ftp.ics.uci.edu/pub/machine-learning-databases/statlog/german/german.doc\n",
    "%cd -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_german = GermanDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `type` of the data object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dataset_german)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIF360 data format\n",
    "\n",
    "All variables of this dataset are described in the [documentation](https://aif360.readthedocs.io/en/latest/modules/generated/aif360.datasets.GermanDataset.html) with more details in the description of the [`StandardDataset`](https://aif360.readthedocs.io/en/latest/modules/generated/aif360.datasets.StandardDataset.html). In short, the dataset class contains a numpy array or pandas DataFrame with several additional variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print a few more details of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'features type: {type(dataset_german.features)}')\n",
    "print(f'labels: {dataset_german.label_names}')\n",
    "print(f'protected attributes: {dataset_german.protected_attribute_names}')\n",
    "print(f'number of features: {len(dataset_german.feature_names)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'feature names: {dataset_german.feature_names}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Or access the help directly in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_german?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore with pandas\n",
    "\n",
    "#### Convert the data to a `features` DataFrame and `labels` Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(dataset_german.features, columns=dataset_german.feature_names)\n",
    "labels = pd.Series(dataset_german.labels.ravel(), name=dataset_german.label_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.describe().transpose().head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[This dataset](https://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29) is already pretty tidy. No missing values and the categorical features are converted into integers. \n",
    "\n",
    ">*Attribute 1*: (qualitative) \\\n",
    ">Status of existing checking account \\\n",
    ">A11 : ... < 0 DM \\\n",
    ">A12 : 0 <= ... < 200 DM \\\n",
    ">A13 : ... >= 200 DM / salary assignments for at least 1 year \\\n",
    ">A14 : no checking account \n",
    "\n",
    "#### The label values are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where 1 = Good, 2 = Bad\n",
    "\n",
    "### Feature distribution\n",
    "\n",
    "#### Plot histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (18,18)\n",
    "\n",
    "features.hist();\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"bias\"></a>\n",
    "## 3.3 Exploring bias metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias metrics\n",
    "\n",
    "> Read <a href=\"https://aif360.readthedocs.io/en/latest/modules/generated/aif360.metrics.BinaryLabelDatasetMetric.html\">the documentation</a> for a full overview of this class and a list of all bias metrics. <a href=\"http://aif360.mybluemix.net/data\">This demo</a> provides explanations and definitions of the metrics as well.<br>\n",
    "\n",
    "\n",
    "#### Group Fairness\n",
    "\n",
    "* Partitions a population into groups defined by protected attributes and seeks for some statistical measure to be equal across groups\n",
    "* Use the metrics in the [DatasetMetric class](https://aif360.readthedocs.io/en/latest/modules/generated/aif360.metrics.DatasetMetric.html)\n",
    "\n",
    "#### Individual Fairness\n",
    "\n",
    "* Seeks for similar individuals to be treated similarly\n",
    "* Use the metrics in the [SampleDistortionMetric class](https://aif360.readthedocs.io/en/latest/modules/generated/aif360.metrics.SampleDistortionMetric.html)\n",
    "\n",
    "#### Or Both\n",
    "\n",
    "* Use the generalized entropy index and its specializations to Theil index and coefficient of variation in the [ClassificationMetric class](https://aif360.readthedocs.io/en/latest/modules/generated/aif360.metrics.ClassificationMetric.html)\n",
    "* Multiple metrics, including ones from both individual and group fairness can be examined simultaneously\n",
    "\n",
    "### Opposing worldviews on group fairness\n",
    "\n",
    "#### We are All Equal (WAE)\n",
    "\n",
    "* All groups have similar abilities with respect to the task (even if we cannot observe this properly)\n",
    "* For example in university admissions, using grades as a feature for predicting success\n",
    "    * the grades may contain structural biases so its distribution being different across groups should not be mistaken for a difference in distribution in ability\n",
    "* Use the demographic parity metrics: `disparate_impact` and `statistical_parity_difference`\n",
    "\n",
    "\n",
    "#### What You See Is What You Get (WYSIWYG) \n",
    "\n",
    "* The observations reflect ability with respect to the task\n",
    "* For example in university admissions, using grades as a feature for predicting success\n",
    "    * the grades correlate well with future success\n",
    "    * there is a way to use the score to correctly compare the abilities of applicants\n",
    "* Use the equality of odds metrics: `average_odds_difference` and `average_abs_odds_difference`\n",
    "\n",
    "#### Equality of opportunity\n",
    "* Other group fairness metrics lie in-between the two worldviews: `false_negative_rate_ratio`, `false_negative_rate_difference`, `false_positive_rate_ratio`, `false_positive_rate_difference`, `false_discovery_rate_ratio`, `false_discovery_rate_difference`, `false_omission_rate_ratio`, `false_omission_rate_difference`, `error_rate_ratio`, and `error_rate_difference`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/MargrietGroenendijk/gitbooks2/blob/master/files/metrics.png?raw=true\" width=\"1000\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `mean_difference`: (alias of `statistical_parity_difference`)\n",
    "    * difference of the rate of favorable outcomes received by the unprivileged group to the privileged group \n",
    "    * a negative value indicates less favorable outcomes for the unprivileged groups\n",
    "    * the ideal value of this metric is 0\n",
    "    * fairness for this metric is between -0.1 and 0.1\n",
    "    \n",
    "* `disparate_impact`: ratio of rate of favorable outcome for the unprivileged group to that of the privileged group\n",
    "     \n",
    "* `equal_opportunity_difference`: (alias of `true_positive_rate_difference`): \n",
    "    * `true_positive_rate`(unprivileged) - `true_positive_rate`(privileged)\n",
    "    * `true_positive_rate`: ratio of true positives to positive examples in the dataset\n",
    "     \n",
    "* `base_rate`: number of positives divided by number of positives plus negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Bias in the credit dataset\n",
    "\n",
    "In the German dataset bias could occur based on age or sex. To explore the age bias: \n",
    "\n",
    "* set the protected attribute to be `age`, where `age >=25` is considered privileged\n",
    "* the protected attribute for `sex` is not consider in this evaluation\n",
    "* set two variables for the privileged (1) and unprivileged (0) values for the age attribute. These are key inputs for detecting and mitigating bias\n",
    "* split the original dataset into training and testing datasets\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    " <b>OPTIONAL EXERCISE</b> <br/> \n",
    " To explore the gender bias in this dataset, edit the below code to use `sex` as the protected attribute and assign new privileged and unprivileged groups.\n",
    "</div>\n",
    "\n",
    "#### Calculate and display the metrics available through the [BinaryLabelDatasetMetric class](https://aif360.readthedocs.io/en/latest/modules/generated/aif360.metrics.BinaryLabelDatasetMetric.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_german = GermanDataset(protected_attribute_names=['age'],\n",
    "                    privileged_classes=[lambda x: x >= 25],      \n",
    "                    features_to_drop=['personal_status', 'sex']) \n",
    "\n",
    "dataset_german_train, dataset_german_test = dataset_german.split([0.7], shuffle=True)\n",
    "\n",
    "privileged_groups = [{'age': 1}]\n",
    "unprivileged_groups = [{'age': 0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_german_train = BinaryLabelDatasetMetric(dataset_german_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "metric_german_test = BinaryLabelDatasetMetric(dataset_german_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metric_german_train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"mean_difference = %f\" % metric_german_train.mean_difference())\n",
    "print(\"disparate_impact = %f\" % metric_german_train.disparate_impact())\n",
    "print(\"base_rate = %f\" % metric_german_train.base_rate())\n",
    "print(\"num_negatives = %f\" % metric_german_train.num_negatives())\n",
    "print(\"num_positives = %f\" % metric_german_train.num_positives())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"model\"></a>\n",
    "## 4. Model building\n",
    "\n",
    "The basics of how a model is created in a supervised machine learning process helps to understand how bias can enter a machine learning model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://nbviewer.jupyter.org/github/IBM/AIF360/blob/master/examples/images/Complex_NoProc_V3.jpg\"   width=\"500\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias can enter the system in any of these three steps:\n",
    "\n",
    ">1. The process starts with a training dataset, which contains a sequence of instances, where each instance has two components: the features and the correct prediction for those features. \n",
    ">2. A machine learning algorithm is trained on this training dataset to produce a machine learning model. This generated model can be used to make a prediction when given a new instance. \n",
    ">3. A second dataset with features and correct predictions, called a test dataset, is used to assess the accuracy of the model. Since this test dataset is the same format as the training dataset, a set of instances of features and prediction pairs, often these two datasets derive from the same initial dataset. A random partitioning algorithm is used to split the initial dataset into training and test datasets.\n",
    "\n",
    "* The **training data** set may be biased in that its outcomes may be biased towards particular kinds of instances\n",
    "* The **algorithm** that creates the model could be biased in that it may generate models that are weighted towards particular features in the input\n",
    "* The **test data** set could be biased as it can have expectations on correct answers that may be biased\n",
    "\n",
    "There are also the three points in the machine learning process for testing and mitigating bias:\n",
    "\n",
    "* pre-processing \n",
    "* in-processing\n",
    "* post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification\n",
    "\n",
    "Some of the model options:\n",
    "* Logistic regression\n",
    "* Decision trees\n",
    "* Random forests\n",
    "* Bayesian networks\n",
    "* Support vector machines\n",
    "* Neural networks\n",
    "\n",
    "<div class=\"alert alert-info\" style=\"font-size:100%\">\n",
    "<b>If you are new to scikit-learn read this <a href=\"https://developer.ibm.com/series/learning-path-machine-learning-for-developers/\">practical introduction</a> for a quick overview.<br>\n",
    "</div>\n",
    "\n",
    "### But first: scale and normalise features\n",
    "\n",
    "* tidy dataset, so this is going to be unrealistically easy, e.g. there are no missing values\n",
    "* one-hot encoding for multiple classes (already done, e.g., [features A11-A14](https://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29))\n",
    "* features need to be standardised, from same distribution\n",
    "\n",
    "[StandardScaler](https://scikit-learn.org/stable/modules/preprocessing.html) - \n",
    "*Standardization of datasets is a common requirement for many machine learning estimators implemented in scikit-learn; they might behave badly if the individual features do not more or less look like standard normally distributed data: Gaussian with zero mean and unit variance. `StandardScaler` implements the Transformer API to compute the mean and standard deviation on a training set so as to be able to later reapply the same transformation on the testing set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_german = StandardScaler().fit(dataset_german_train.features)\n",
    "\n",
    "X_train = scale_german.transform(dataset_german_train.features)\n",
    "y_train = dataset_german_train.labels.ravel()\n",
    "w_train = dataset_german_train.instance_weights.ravel()\n",
    "\n",
    "X_test = scale_german.transform(dataset_german_test.features)\n",
    "y_test = dataset_german_test.labels.ravel()\n",
    "w_test = dataset_german_test.instance_weights.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What does the data look like now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (18,18)\n",
    "\n",
    "scaled_features = pd.DataFrame(X_train, columns=dataset_german.feature_names)\n",
    "\n",
    "scaled_features.hist();\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"original\"></a>\n",
    "### 4.1 Train on the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression classifier and predictions\n",
    "\n",
    "# create an instance of the model\n",
    "lmod = LogisticRegression()\n",
    "\n",
    "# train the model\n",
    "lmod.fit(X_train, y_train, \n",
    "         sample_weight=dataset_german_train.instance_weights)\n",
    "\n",
    "# calculate predicted labels\n",
    "y_train_pred = lmod.predict(X_train)\n",
    "\n",
    "# assign positive class index\n",
    "pos_ind = np.where(lmod.classes_ == dataset_german_train.favorable_label)[0][0]\n",
    "\n",
    "# add predicted labels to predictions dataset\n",
    "dataset_german_train_pred = dataset_german_train.copy()\n",
    "dataset_german_train_pred.labels = y_train_pred\n",
    "\n",
    "dataset_german_test_pred = dataset_german_test.copy()\n",
    "X_test = scale_german.transform(dataset_german_test_pred.features)\n",
    "y_test_pred = lmod.predict(X_test)\n",
    "pos_ind_test = np.where(lmod.classes_ == dataset_german_test.favorable_label)[0][0]\n",
    "dataset_german_test_pred.labels = lmod.predict(X_test)\n",
    "\n",
    "\n",
    "#y_test = dataset_german_test_pred.labels\n",
    "#dataset_german_test_pred.labels = lmod.predict_proba(X_test)[:,pos_ind].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model accuracy\n",
    "score = lmod.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, lmod.predict(X_test))\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "[fig, ax] = plt.subplots(1, figsize=(5, 5));\n",
    "plot_confusion_matrix(lmod, X_test, y_test,\n",
    "                      cmap=plt.cm.Blues, \n",
    "                      display_labels=['good credit','bad credit'],\n",
    "                      normalize='true',ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(dataset_german_test.features, columns=dataset_german_test.feature_names)\n",
    "\n",
    "[fig, ax] = plt.subplots(1,2, figsize=(15, 5));\n",
    "plot_confusion_matrix(lmod, X_test[df_test['age']==0], y_test[df_test['age']==0],\n",
    "                      cmap=plt.cm.Blues, \n",
    "                      display_labels=['good credit','bad credit'],\n",
    "                      ax=ax[0],normalize='true');\n",
    "ax[0].set_title('Age < 25')\n",
    "\n",
    "plot_confusion_matrix(lmod, X_test[df_test['age']==1], y_test[df_test['age']==1],\n",
    "                      cmap=plt.cm.Blues, \n",
    "                      display_labels=['good credit','bad credit'],\n",
    "                      ax=ax[1],normalize='true');\n",
    "ax[1].set_title('Age > 25');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model metrics from the [`ClassificationMetric` class](https://aif360.readthedocs.io/en/latest/modules/generated/aif360.metrics.ClassificationMetric.html)\n",
    "\n",
    "aif360 contains several metrics to compare the bias in the data and the predictions. \n",
    "\n",
    "#### Calculate the metrics ob both the training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_german_train_pred = ClassificationMetric(dataset_german_train, dataset_german_train_pred,\n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "metric_german_pred = ClassificationMetric(dataset_german_test, dataset_german_test_pred,\n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"mean_difference = %f\" % metric_german_train.mean_difference())\n",
    "print(\"disparate_impact = %f\" % metric_german_train.disparate_impact())\n",
    "\n",
    "display(Markdown(\"#### Original test dataset\"))\n",
    "print(\"mean_difference = %f\" % metric_german_test.mean_difference())\n",
    "print(\"disparate_impact = %f\" % metric_german_test.disparate_impact())\n",
    "\n",
    "display(Markdown(\"#### Predicted labels (training dataset)\"))\n",
    "print(\"mean_difference = %f\" % metric_german_train_pred.mean_difference())\n",
    "print(\"disparate_impact = %f\" % metric_german_train_pred.disparate_impact())\n",
    "\n",
    "display(Markdown(\"#### Predicted labels (test dataset)\"))\n",
    "print(\"mean_difference = %f\" % metric_german_pred.mean_difference())\n",
    "print(\"disparate_impact = %f\" % metric_german_pred.disparate_impact())\n",
    "\n",
    "display(Markdown(\"#### Quality metrics  (training dataset)\"))\n",
    "print(\"accuracy = %f\" % metric_german_train_pred.accuracy())\n",
    "print(\"coefficient_of_variation = %f\" % metric_german_train_pred.coefficient_of_variation())\n",
    "print(\"error_rate = %f\" % metric_german_train_pred.error_rate())\n",
    "\n",
    "display(Markdown(\"#### Quality metrics  (test dataset)\"))\n",
    "print(\"accuracy = %f\" % metric_german_pred.accuracy())\n",
    "print(\"coefficient_of_variation = %f\" % metric_german_pred.coefficient_of_variation())\n",
    "print(\"error_rate = %f\" % metric_german_pred.error_rate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"algorithms\"></a>\n",
    "## 5. AI fairness algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/MargrietGroenendijk/gitbooks2/blob/master/files/pipeline.png?raw=true\" width=\"1000\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/MargrietGroenendijk/gitbooks2/blob/master/files/algorithms.png?raw=true\"  width=\"1000\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"preproc\"></a>\n",
    "### 5.1 Pre-processing algorithms\n",
    "\n",
    "### Remove bias by reweighing data\n",
    "\n",
    "**Reweighing** is a preprocessing technique that weights the examples in each (group, label) combination differently to ensure fairness before classification.\n",
    "\n",
    "<div class=\"alert alert-info\" style=\"font-size:100%\">\n",
    "<b>Read the <a href=\"https://aif360.readthedocs.io/en/latest/modules/generated/aif360.algorithms.preprocessing.Reweighing.html\">aif360 documentation</a> for a full overview<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "               privileged_groups=privileged_groups)\n",
    "\n",
    "# compute the weights for reweighing the dataset\n",
    "RW.fit(dataset_german_train)\n",
    "\n",
    "# transform the dataset to a new dataset based on the estimated transformation\n",
    "dataset_rw_train = RW.transform(dataset_german_train)\n",
    "dataset_rw_test = RW.transform(dataset_german_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"mean_difference = %f\" % metric_german_train.mean_difference())\n",
    "print(\"disparate_impact = %f\" % metric_german_train.disparate_impact())\n",
    "\n",
    "metric_rw_train = BinaryLabelDatasetMetric(dataset_rw_train, \n",
    "                                         unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)\n",
    "\n",
    "display(Markdown(\"#### Reweighted training dataset\"))\n",
    "print(\"mean_difference = %f\" % metric_rw_train.mean_difference())\n",
    "print(\"disparate_impact = %f\" % metric_rw_train.disparate_impact())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train on reweighted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data\n",
    "scale_rw = StandardScaler().fit(dataset_rw_train.features)\n",
    "\n",
    "X_train_rw = scale_rw.transform(dataset_rw_train.features)\n",
    "y_train_rw = dataset_rw_train.labels.ravel()\n",
    "w_train_rw = dataset_rw_train.instance_weights.ravel()\n",
    "\n",
    "X_test_rw = scale_rw.transform(dataset_rw_test.features)\n",
    "y_test_rw = dataset_rw_test.labels.ravel()\n",
    "w_test_rw = dataset_rw_test.instance_weights.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_rw_train.instance_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new instance of the model\n",
    "lmod_rw = LogisticRegression()\n",
    "\n",
    "# train the model\n",
    "lmod_rw.fit(X_train_rw, y_train_rw, \n",
    "         sample_weight=dataset_rw_train.instance_weights)\n",
    "\n",
    "# calculate predicted labels\n",
    "y_train_pred_rw = lmod_rw.predict(X_train_rw)\n",
    "\n",
    "# assign positive class index\n",
    "pos_ind_rw = np.where(lmod_rw.classes_ == dataset_rw_train.favorable_label)[0][0]\n",
    "\n",
    "# add predicted labels to predictions dataset\n",
    "dataset_rw_train_pred = dataset_rw_train.copy()\n",
    "dataset_rw_train_pred.labels = y_train_pred_rw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model accuracy\n",
    "print(score)\n",
    "score_rw = lmod_rw.score(X_test_rw, y_test_rw)\n",
    "print(score_rw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "cm_rw = metrics.confusion_matrix(y_test_rw, lmod_rw.predict(X_test_rw))\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(cm_rw, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Purples');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "plt.title('Reweighted model');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[fig, ax] = plt.subplots(2,2, figsize=(15, 12));\n",
    "plot_confusion_matrix(lmod, X_test[df_test['age']==0], y_test[df_test['age']==0],\n",
    "                      cmap=plt.cm.OrRd, \n",
    "                      display_labels=['good credit','bad credit'],\n",
    "                      ax=ax[0,0]);\n",
    "ax[0,0].set_title('Age < 25')\n",
    "\n",
    "plot_confusion_matrix(lmod, X_test[df_test['age']==1], y_test[df_test['age']==1],\n",
    "                      cmap=plt.cm.PuBu, \n",
    "                      display_labels=['good credit','bad credit'],\n",
    "                      ax=ax[0,1]);\n",
    "ax[0,1].set_title('Age > 25');\n",
    "\n",
    "plot_confusion_matrix(lmod_rw, X_test_rw[df_test['age']==0], y_test_rw[df_test['age']==0],\n",
    "                      cmap=plt.cm.OrRd, \n",
    "                      display_labels=['good credit','bad credit'],\n",
    "                      ax=ax[1,0]);\n",
    "ax[1,0].set_title('Age < 25 (Reweighted)')\n",
    "\n",
    "plot_confusion_matrix(lmod_rw, X_test_rw[df_test['age']==1], y_test_rw[df_test['age']==1],\n",
    "                      cmap=plt.cm.PuBu, \n",
    "                      display_labels=['good credit','bad credit'],\n",
    "                      ax=ax[1,1]);\n",
    "ax[1,1].set_title('Age > 25 (Reweighted)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[fig, ax] = plt.subplots(2,2, figsize=(15, 12), sharex=True);\n",
    "plot_confusion_matrix(lmod, X_test[df_test['age']==0], y_test[df_test['age']==0],\n",
    "                      cmap=plt.cm.PuBu, \n",
    "                      display_labels=['good credit','bad credit'],\n",
    "                      ax=ax[0,0],normalize='true');\n",
    "ax[0,0].set_title('Age < 25')\n",
    "\n",
    "plot_confusion_matrix(lmod, X_test[df_test['age']==1], y_test[df_test['age']==1],\n",
    "                      cmap=plt.cm.PuBu, \n",
    "                      display_labels=['good credit','bad credit'],\n",
    "                      ax=ax[0,1],normalize='true');\n",
    "ax[0,1].set_title('Age > 25');\n",
    "\n",
    "plot_confusion_matrix(lmod_rw, X_test_rw[df_test['age']==0], y_test_rw[df_test['age']==0],\n",
    "                      cmap=plt.cm.PuBu, \n",
    "                      display_labels=['good credit','bad credit'],\n",
    "                      ax=ax[1,0],normalize='true');\n",
    "ax[1,0].set_title('Age < 25 (Reweighted)')\n",
    "\n",
    "plot_confusion_matrix(lmod_rw, X_test_rw[df_test['age']==1], y_test_rw[df_test['age']==1],\n",
    "                      cmap=plt.cm.PuBu, \n",
    "                      display_labels=['good credit','bad credit'],\n",
    "                      ax=ax[1,1],normalize='true');\n",
    "ax[1,1].set_title('Age > 25 (Reweighted)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove bias with the optimized data pre-processing algorithm \n",
    "\n",
    "The debiasing function used is implemented in the [OptimPreproc](https://aif360.readthedocs.io/en/latest/modules/generated/aif360.algorithms.preprocessing.OptimPreproc.html?highlight=get%20distortion) class. It modifies training data features & labels.\n",
    "\n",
    "* Define parameters for optimized pre-processing specific to the dataset.\n",
    "* Divide the dataset into training, validation, and testing partitions.\n",
    "* Learn the optimized pre-processing transformation from the training data.\n",
    "* Train classifier on original training data.\n",
    "* Estimate the optimal classification threshold, that maximizes balanced accuracy without fairness constraints (from the original validation set).\n",
    "* Determine the prediction scores for original testing data. Using the estimated optimal classification threshold, compute accuracy and fairness metrics.\n",
    "* Transform the testing set using the learned probabilistic transformation.\n",
    "* Determine the prediction scores for transformed testing data. Using the estimated optimal classification threshold, compute accuracy and fairness metrics.\n",
    "\n",
    "> Example notebook [here](https://github.com/Trusted-AI/AIF360/blob/master/examples/demo_optim_data_preproc.ipynb)\n",
    "\n",
    "This algorithm does not use the privileged and unprivileged groups that are specified during initialization yet. Instead, it automatically attempts to reduce statistical parity difference between all possible combinations of groups in the dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"inproc\"></a>\n",
    "### 5.2 In-processing algorithms\n",
    "\n",
    "Examples:\n",
    "* [Adversarial Debiasing](https://github.com/Trusted-AI/AIF360/blob/master/examples/demo_adversarial_debiasing.ipynb) - Uses adversarial techniques to maximize accuracy & reduce evidence of protected attributes in predictions\n",
    "* [Reject Option Classification](https://github.com/Trusted-AI/AIF360/blob/master/examples/demo_reject_option_classification.ipynb) - Adds a discrimination-aware regularization term to the learning objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"postproc\"></a>\n",
    "### 5.3 Post-processing algorithms\n",
    "\n",
    "* [Reject option classification (ROC)](https://aif360.readthedocs.io/en/latest/modules/generated/aif360.algorithms.postprocessing.RejectOptionClassification.html?highlight=reject) is a postprocessing technique that gives favorable outcomes to unpriviliged groups and unfavorable outcomes to priviliged groups in a confidence band around the decision boundary with the highest uncertainty.\n",
    "* [Odds Equalizing](https://github.com/Trusted-AI/AIF360/blob/master/examples/demo_calibrated_eqodds_postprocessing.ipynb) modifies the predicted label using an optimization scheme to make predictions fairer\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beyond accuracy\n",
    "\n",
    "Tradeoffs – Bias vs. Accuracy\n",
    "\n",
    "* Is your model doing good things or bad things to people?\n",
    "    * If your model is sending people to jail, may be better to have more false positives than false negatives     \n",
    "    * If your model is handing out loans, may be better to have more False Negatives than False Positives\n",
    "* Determine your threshold for accuracy vs. fairness\n",
    "    * Doing what is **legal** is top priority \n",
    "    * What are the **ethical** guidelines of your company? \n",
    "    * Losing the **trust** of your customers is costly \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"resources\"></a>\n",
    "# 5. More resources\n",
    "\n",
    "* [aif360 demo and resources](http://aif360.mybluemix.net/)\n",
    "* [aif360 on GitHub](https://github.com/Trusted-AI/AIF360)\n",
    "* [Python API documentation](https://aif360.readthedocs.io/en/latest/)\n",
    "* [R documentation](https://github.com/Trusted-AI/AIF360/tree/master/aif360/aif360-r)\n",
    "* [Medical expenditure tutorial](https://nbviewer.jupyter.org/github/IBM/AIF360/blob/master/examples/tutorial_medical_expenditure.ipynb)\n",
    "\n",
    "Copyright © 2020 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6 (aif360)",
   "language": "python",
   "name": "aif360"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
